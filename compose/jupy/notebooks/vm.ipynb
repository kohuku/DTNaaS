{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time\n",
    "from prometheus_http_client import Prometheus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from http.client import HTTPException\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTN(object):\n",
    "    def __init__(self, name, man_addr, data_addr, mon_addr, interface):\n",
    "        self.name = name\n",
    "        self.man_addr = man_addr\n",
    "        self.data_addr = data_addr\n",
    "        self.interface = interface\n",
    "        self.mon_addr = mon_addr\n",
    "\n",
    "# register DTN to orchestrator\n",
    "def add_dtn_to_orchestrator(sender, receiver, orchestrator):\n",
    "\n",
    "    data = {\n",
    "        'name': 'receiver',\n",
    "        'man_addr': receiver.man_addr,\n",
    "        'data_addr': receiver.data_addr,\n",
    "        'username': 'nobody',\n",
    "        'interface': receiver.interface\n",
    "    }\n",
    "    # register receiver and get ID 1\n",
    "    response = requests.get('{}'.format(orchestrator))\n",
    "    print(response)\n",
    "    response = requests.post('{}/DTN/'.format(orchestrator), json=data)    \n",
    "    result = response.json()\n",
    "    print('receiver : ',result)\n",
    "    #assert result == {'id': 8}\n",
    "    \n",
    "    data = {\n",
    "        'name': 'sender',\n",
    "        'man_addr': sender.man_addr,\n",
    "        'data_addr': sender.data_addr,\n",
    "        'username': 'nobody',        \n",
    "        'interface': sender.interface\n",
    "    }\n",
    "    # register sender and get ID 2\n",
    "    response = requests.post('{}/DTN/'.format(orchestrator), json=data)\n",
    "    result = response.json()\n",
    "    print('sender : ',result)\n",
    "    #assert result == {'id': 9}\n",
    "    \n",
    "\n",
    "\n",
    "receiver = DTN('vm_kodai2','192.168.10.141:5000', '192.168.10.141', '192.168.10.141:5000',  'enp1s0')\n",
    "sender = DTN('vm_kodai1', '192.168.10.113:5000', '192.168.10.113', '192.168.10.113:5000', 'enp1s0')\n",
    "orchestrator = 'http://192.168.10.113:5002'\n",
    "monitor = 'http://192.168.10.156:9090'\n",
    "\n",
    "# DTNs already added\n",
    "#add_dtn_to_orchestrator(sender,receiver,orchestrator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVG_INT = 15\n",
    "STEP = 15\n",
    "MAX_RES = 11000\n",
    "\n",
    "\n",
    "# check latency between DTNs\n",
    "def test_ping(orchestrator):\n",
    "    response = requests.get('{}/ping/10/9'.format(orchestrator))\n",
    "    result = response.json()\n",
    "    print(result)\n",
    "\n",
    "\n",
    "# Start Transfer from sender to receiver on /data directory\n",
    "def test_transfer(sender, receiver, orchestrator, num_workers = 2):   \n",
    "    # retrieve files from sender \n",
    "    result =  requests.get('http://{}/files/'.format(sender.man_addr))    \n",
    "\n",
    "    # classify files and dirs from returned list\n",
    "    files = result.json()\n",
    "    file_list = [i['name'] for i in files if i['type'] == 'file'][:5]\n",
    "    dirs = [i['name'] for i in files if i['type'] == 'dir']\n",
    "    print(file_list,dirs)\n",
    "\n",
    "    # create dirs in receiver\n",
    "    response = requests.post('http://{}/create_dir/'.format(receiver.man_addr),json=dirs)\n",
    "    if response.status_code != 200: raise Exception('failed to create dirs')\n",
    "\n",
    "    # prepare files to send \n",
    "    data = {\n",
    "        # list of files to send\n",
    "        'srcfile' : file_list,\n",
    "        # list of files to receive\n",
    "        'dstfile' : file_list,\n",
    "        # number of simultaneous connections\n",
    "        'num_workers' : num_workers,\n",
    "        # block size to use\n",
    "        'blocksize' : 1024,\n",
    "        # disable zero-copy\n",
    "        'zerocopy' : False,\n",
    "    }\n",
    "\n",
    "    print('send data',data)\n",
    "    # start transfer using nuttcp\n",
    "    response = requests.post('{}/transfer/nuttcp/10/9'.format(orchestrator),json=data) \n",
    "    result = response.json()\n",
    "    #print(result)\n",
    "    assert result['result'] == True\n",
    "    transfer_id = result['transfer']\n",
    "    print('transfer_id %s' % (transfer_id))\n",
    "    return transfer_id\n",
    "\n",
    "# clean up DTNs after transfer\n",
    "def cleanup(sender, receiver, retry = 5):\n",
    "\n",
    "    for i in range(0, retry):        \n",
    "        response = requests.get('http://{}/cleanup/nuttcp'.format(sender.man_addr))\n",
    "        if response.status_code != 200: continue\n",
    "        response = requests.get('http://{}/cleanup/nuttcp'.format(receiver.man_addr))\n",
    "        if response.status_code != 200: continue        \n",
    "        \n",
    "        return \n",
    "    raise Exception('Cannot cleanup after %s tries' % retry)\n",
    "\n",
    "# wait for transfer to finish\n",
    "def wait_for_transfer(transfer_id, orchestrator, sender):\n",
    "    while True:\n",
    "        response = requests.get('{}/check/{}'.format(orchestrator, transfer_id))\n",
    "        result = response.json()\n",
    "        print(result)\n",
    "        if result['Unfinished'] == 0:\n",
    "            response = requests.get('http://{}/cleanup/nuttcp'.format(sender.man_addr))\n",
    "            break\n",
    "        time.sleep(3)\n",
    "\n",
    "# mark transfer to finished\n",
    "def finish_transfer(transfer_id, orchestrator, sender, receiver):    \n",
    "    response = requests.post('{}/wait/{}'.format(orchestrator, transfer_id))\n",
    "    result = response.json()\n",
    "    print(\"finish_transfer result\",result)\n",
    "    cleanup(sender, receiver)\n",
    "\n",
    "# get transfer detail\n",
    "def get_transfer(transfer_id, orchestrator):\n",
    "    \n",
    "    response = requests.get('{}/transfer/{}'.format(orchestrator, transfer_id))\n",
    "    result = response.json()\n",
    "    print('get_transfer_result',result)\n",
    "    return result\n",
    "\n",
    "# send data query to DTNs\n",
    "def send_query(query, start, end, step, url):\n",
    "    \n",
    "    prometheus = Prometheus()\n",
    "    prometheus.url = url\n",
    "\n",
    "    res = prometheus.query_rang(metric=query, start=start, end=end, step=step)    \n",
    "    return res\n",
    "\n",
    "# remove unnecessary header for dataset\n",
    "def prettify_header(metric):\n",
    "    metrics_to_remove = ['instance', 'job', 'mode', '__name__', 'container', 'endpoint', 'namespace', 'pod', 'prometheus', 'service']\n",
    "    for i in metrics_to_remove:\n",
    "        if i in metric: del metric[i]\n",
    "    if len(metric) > 1 : raise Exception('too many metric labels')\n",
    "    else:\n",
    "        return next(iter(metric.keys()))\n",
    "\n",
    "# extract data from monitoring system\n",
    "def extractor(sender, receiver, start_time, end_time, monitor_url):\n",
    "    AVG_INT = 15        \n",
    "    query = (\n",
    "    'label_replace(sum by (instance)(irate(node_network_transmit_bytes_total{{instance=~\"{4}.*\", device=\"{2}\"}}[{1}m])), \"network_throughput\", \"$0\", \"instance\", \"(.+)\") '\n",
    "    'or label_replace(sum by (job)(irate(node_disk_written_bytes_total{{instance=~\"{5}.*\", device=~\"nvme.*\"}}[{1}m])),\"Goodput\", \"$0\", \"job\", \"(.+)\") '        \n",
    "    'or label_replace(sum by (job)(1 - irate(node_cpu_seconds_total{{mode=\"idle\", instance=\"{4}\"}}[1m])),\"CPU\", \"$0\", \"job\", \"(.+)\") '\n",
    "    'or label_replace(max by (container)(container_memory_working_set_bytes{{namespace=\"{3}\", container=~\"{0}.*\"}}), \"Memory_used\", \"$0\", \"container\", \"(.+)\") '\n",
    "    'or label_replace(node_memory_Active_bytes{{instance=\"{4}\"}}, \"Memory_used\", \"$0\", \"instance\", \"(.+)\") '    \n",
    "    'or label_replace(sum by (job)(irate(node_disk_read_bytes_total{{instance=~\"{4}.*\", device=~\"nvme.*\"}}[{1}m])),\"NVMe_transfer_bytes\", \"$0\", \"job\", \"(.+)\") '\n",
    "    'or label_replace(sum by (job)(irate(node_disk_io_time_seconds_total{{instance=~\"{4}.*\", device=~\"nvme.*\"}}[{1}m])),\"NVMe_total_util\", \"$0\", \"job\", \"(.+)\") '    \n",
    "    'or label_replace(count by (job)(node_disk_io_time_seconds_total{{instance=~\"{4}.*\", device=~\"nvme[0-7]n1\"}}),\"Storage_count\", \"$0\", \"job\", \"(.+)\") '\n",
    "    'or label_replace(sum by (job)(node_network_speed_bytes{{instance=~\"{4}.*\", device=\"{2}\"}} * 8), \"NIC_speed\", \"$0\", \"job\", \"(.+)\") '\n",
    "    'or label_replace(sum by (job)(irate(node_netstat_Tcp_RetransSegs{{instance=~\"{4}.*\"}}[{1}m])), \"Packet_losses\", \"$0\", \"job\", \"(.+)\") '\n",
    "    '').format(sender.name, AVG_INT, sender.interface, 'dtnaas', sender.mon_addr, receiver.mon_addr)\n",
    "\n",
    "    dataset = None\n",
    "    \n",
    "    while end_time > start_time:        \n",
    "        data_in_period = None\n",
    "        max_ts = start_time + (STEP * MAX_RES) \n",
    "        next_hop_ts = end_time if max_ts > end_time else max_ts\n",
    "        logging.debug('Getting data for {} : {}'.format(start_time, end_time))\n",
    "        res = send_query(query, start_time, next_hop_ts, STEP, monitor_url)\n",
    "        print(res)\n",
    "        if '401 Authorization Required' in res: raise HTTPException(res)\n",
    "        response = json.loads(res)\n",
    "        if response['status'] != 'success': raise Exception('Failed to query Prometheus server')\n",
    "        #print(response)\n",
    "        for result in response['data']['result']:\n",
    "            result['metric'] = prettify_header(result['metric'])            \n",
    "            df = pd.DataFrame(data=result['values'], columns = ['Time', result['metric']], dtype=float)            \n",
    "            df['Time'] = pd.to_datetime(df['Time'], unit='s')\n",
    "            df.set_index('Time', inplace=True)\n",
    "\n",
    "            data_in_period = df if data_in_period is None else data_in_period.merge(df, how='outer',  on='Time').sort_index()\n",
    "        \n",
    "        dataset = data_in_period if dataset is None else dataset.append(data_in_period)\n",
    "        start_time = next_hop_ts\n",
    "\n",
    "    cols = dataset.columns.tolist()\n",
    "    labels_to_rearrange = ['NVMe_total_util', 'NVMe_transfer_bytes']    \n",
    "    for i in labels_to_rearrange: \n",
    "        cols.remove(i)\n",
    "        cols.insert(0,i)    \n",
    "    \n",
    "    return dataset[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ping ( orchestrator )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest Ping ( orchestrator )\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m test_ping(orchestrator)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mStart Transfer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# start transfer\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mtest_ping\u001b[0;34m(orchestrator)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_ping\u001b[39m(orchestrator):\n\u001b[0;32m----> 8\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/ping/10/9\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(orchestrator))\n\u001b[1;32m      9\u001b[0m     result \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m     conn\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    497\u001b[0m         method,\n\u001b[1;32m    498\u001b[0m         url,\n\u001b[1;32m    499\u001b[0m         body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    500\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    501\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    502\u001b[0m         preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    503\u001b[0m         decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    504\u001b[0m         enforce_content_length\u001b[39m=\u001b[39;49menforce_content_length,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[39m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[39m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:395\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39mfor\u001b[39;00m header, value \u001b[39min\u001b[39;00m headers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    394\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mputheader(header, value)\n\u001b[0;32m--> 395\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendheaders()\n\u001b[1;32m    397\u001b[0m \u001b[39m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39mif\u001b[39;00m chunks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39;49mencode_chunked)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer)\n\u001b[1;32m   1040\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(msg)\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(message_body, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1047\u001b[0m         \u001b[39m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m         \u001b[39m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m         \u001b[39m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m    980\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m         \u001b[39mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:243\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    244\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n\u001b[1;32m    245\u001b[0m         \u001b[39m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_connected_to_proxy \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/connection.py:203\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[1;32m    200\u001b[0m \u001b[39m:return: New socket connection.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    204\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    205\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    206\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    207\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     72\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     74\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m     75\u001b[0m err \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Test Ping ( orchestrator )\")\n",
    "test_ping(orchestrator)\n",
    "\n",
    "print (\"Start Transfer\")\n",
    "# start transfer\n",
    "transfer_id = test_transfer(sender, receiver, orchestrator)\n",
    "\n",
    "print(\" waiting for transfer to finish\")\n",
    "wait_for_transfer(transfer_id, orchestrator, sender)\n",
    "print(\"Transfer finished\")\n",
    "# mark transfer to finished\n",
    "finish_transfer(transfer_id, orchestrator, sender, receiver)\n",
    "\n",
    "# get transfer detail\n",
    "transfer_detail = get_transfer(transfer_id, orchestrator)\n",
    "print(transfer_detail,\"1\")\n",
    "# use the transfer detail to query dataset\n",
    "df = extractor(sender, receiver, transfer_detail['start_time'], transfer_detail['end_time'], monitor)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
